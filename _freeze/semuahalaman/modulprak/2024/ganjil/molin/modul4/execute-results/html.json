{
  "hash": "72732ed3575efe6b1c0acc5cdb5c4bae",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model Building\"\nsubtitle: \"Model Building & Model Validation\"\nimage: static\\Plot regresi.png\ndescription: \"Offline di Departemen Matematika\"\ndate: 11/4/2024\npage-navigation: true\nformat:\n  html:\n    code-overflow: wrap\nknitr:\n  opts_chunk:\n    comment: ''\nformat-links: false\ninclude-in-header:\n  - text: |\n      <style>\n      .cell-output-stdout code {\n        word-break: break-wor !important;\n        white-space: pre-wrap !important;\n      }\n      </style>\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n# Model Building\n\nApa Itu Model Building? Model building adalah proses membuat model yang\nbisa cocok dengan data yang kita miliki dan bisa memberikan prediksi\nyang baik untuk masa depan. Dalam konteks analisis regresi, ini berarti\nmemilih bentuk model yang bisa menunjukkan hubungan antara hasil yang\nkita prediksi $(y)$ dan variabel-variabel **yang** memengaruhi hasil\ntersebut $(x_1,x_2,...,x_k).$\n\nKenapa Proses Ini Penting? Proses model building sangat penting karena\nmenentukan seberapa baik model kita bisa bekerja. Jika model yang kita\nbuat tidak mencerminkan hubungan yang sebenarnya antara\nvariabel-variabel, maka model tersebut tidak akan memberikan hasil yang\nakurat dan bisa menyebabkan kesalahan dalam analisis atau prediksi.\n\nLangkah-langkah dalam Model Building:\n\n1.  Identifikasi Variabel Respons (Y): Tentukan variabel dependen yang\n    ingin diprediksi atau dianalisis.\n\n2.  Klasifikasi Variabel Prediktor: Kelompokkan variabel independen\n    sebagai variabel kuantitatif (yang diukur dengan angka) atau\n    kualitatif (yang berupa kategori).\n\n3.  Gunakan Dummy Variables: Jika ada variabel kualitatif, ubah variabel\n    tersebut menjadi dummy variables agar bisa dimasukkan ke dalam\n    model.\n\n4.  Pertimbangkan Derajat Lebih Tinggi: Untuk variabel kuantitatif,\n    pertimbangkan untuk menambahkan komponen seperti $X^2$ atau $X^3$\n    untuk menangkap hubungan non-linier yang mungkin ada.\n\n5.  Gunakan Polinomial Derajat Tinggi: Jika relevan, kodekan variabel\n    kuantitatif dalam bentuk polinomial agar model bisa lebih fleksibel\n    dalam menangkap pola data.\n\n6.  Tambahkan Interaksi Antar Variabel: Pertimbangkan untuk menambahkan\n    interaksi antara variabel kuantitatif dan kualitatif untuk melihat\n    efek gabungan mereka terhadap variabel respons.\n\n7.  Bandingkan Model Bertingkat (Nested Models): Gunakan uji partial\n    F-test untuk membandingkan model sederhana dengan model yang lebih\n    kompleks dan pilih model yang terbaik.\n\n8.  Validasi Model: Pastikan model akhir diuji dengan data yang berbeda\n    (misalnya, menggunakan metode cross-validation atau jackknife) untuk\n    memastikan bahwa model tersebut dapat diandalkan untuk prediksi di\n    luar data pelatihan (data training).\n\n## Penerapan Model Building\n\n1.  Identifikasi Variabel Respons (Y)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(AER)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: car\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: carData\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lmtest\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: zoo\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'zoo'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: sandwich\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: survival\n```\n\n\n:::\n\n```{.r .cell-code}\ndata('mtcars')\nhead(mtcars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(mtcars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n```\n\n\n:::\n:::\n\n\n\n2.  Klasifikasi Variabel Prediktor\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncategorical = c(\"cyl\", \"vs\", \"am\", \"gear\", \"carb\")\nmtcars[categorical] <- lapply(mtcars[categorical], as.factor)\nstr(mtcars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : Factor w/ 3 levels \"4\",\"6\",\"8\": 2 2 1 2 3 2 3 1 1 2 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : Factor w/ 2 levels \"0\",\"1\": 1 1 2 2 1 2 1 2 2 2 ...\n $ am  : Factor w/ 2 levels \"0\",\"1\": 2 2 2 1 1 1 1 1 1 1 ...\n $ gear: Factor w/ 3 levels \"3\",\"4\",\"5\": 2 2 2 1 1 1 1 2 2 2 ...\n $ carb: Factor w/ 6 levels \"1\",\"2\",\"3\",\"4\",..: 4 4 1 1 2 1 4 2 2 4 ...\n```\n\n\n:::\n:::\n\n\n\n3.  Gunakan Dummy Variables untuk Variabel Kualitatif\n\n    Variabel kualitatif yang sudah diubah menjadi faktor di step\n    sebelumnya di-dummy-kan secara otomatis oleh R saat digunakan dalam\n    fungsi lm().\n\n4.  Pertimbangkan Derajat Lebih Tinggi\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 = lm(mpg ~ disp, data = mtcars)\nmodel2 = lm(mpg ~ disp + I(disp^2), data = mtcars)\n```\n:::\n\n\n\nVisualisasi\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mtcars$disp, mtcars$mpg, main = 'Perbandingan Regresi Linier Sederhana dan Derajat 2', xlab = 'disp', ylab = 'mpg')\nlines(mtcars$disp, predict(model1), col = 'blue', lwd = 3)\nlines(sort(mtcars$disp), predict(model2)[order(mtcars$disp)], col = 'darkgreen', lwd = 3)\nlegend('topright', legend = c('Derajat 1', 'Derajat 2'), col = c('blue', 'darkgreen'), lty = 1, cex = 1, lwd = 3)\n```\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n5.  Tambahkan Interaksi Antar Variabel\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_interaction = lm(mpg ~ disp * hp, data = mtcars)\nsummary(model_interaction)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ disp * hp, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5153 -1.6315 -0.6346  0.9038  5.7030 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.967e+01  2.914e+00  13.614 7.18e-14 ***\ndisp        -7.337e-02  1.439e-02  -5.100 2.11e-05 ***\nhp          -9.789e-02  2.474e-02  -3.956 0.000473 ***\ndisp:hp      2.900e-04  8.694e-05   3.336 0.002407 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.692 on 28 degrees of freedom\nMultiple R-squared:  0.8198,\tAdjusted R-squared:  0.8005 \nF-statistic: 42.48 on 3 and 28 DF,  p-value: 1.499e-10\n```\n\n\n:::\n:::\n\n\n\n6.  Bandingkan Nested Model\n\n    Menggunakan metode seleksi forward, backward, dan both direction.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_intercept = lm(mpg ~ 1, data = mtcars)\nmodel_full = lm(mpg ~ ., data = mtcars)\n\n# Forward selection\nforward = step(model_intercept, direction = 'forward', scope = formula(model_full), trace = 0)\nsummary(forward)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt + cyl + hp + am, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9387 -1.2560 -0.4013  1.1253  5.0513 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 33.70832    2.60489  12.940 7.73e-13 ***\nwt          -2.49683    0.88559  -2.819  0.00908 ** \ncyl6        -3.03134    1.40728  -2.154  0.04068 *  \ncyl8        -2.16368    2.28425  -0.947  0.35225    \nhp          -0.03211    0.01369  -2.345  0.02693 *  \nam1          1.80921    1.39630   1.296  0.20646    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.41 on 26 degrees of freedom\nMultiple R-squared:  0.8659,\tAdjusted R-squared:  0.8401 \nF-statistic: 33.57 on 5 and 26 DF,  p-value: 1.506e-10\n```\n\n\n:::\n\n```{.r .cell-code}\n# Backward selection\nbackward = step(model_full, direction = 'backward', trace = 0)\nsummary(backward)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ cyl + hp + wt + am, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9387 -1.2560 -0.4013  1.1253  5.0513 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 33.70832    2.60489  12.940 7.73e-13 ***\ncyl6        -3.03134    1.40728  -2.154  0.04068 *  \ncyl8        -2.16368    2.28425  -0.947  0.35225    \nhp          -0.03211    0.01369  -2.345  0.02693 *  \nwt          -2.49683    0.88559  -2.819  0.00908 ** \nam1          1.80921    1.39630   1.296  0.20646    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.41 on 26 degrees of freedom\nMultiple R-squared:  0.8659,\tAdjusted R-squared:  0.8401 \nF-statistic: 33.57 on 5 and 26 DF,  p-value: 1.506e-10\n```\n\n\n:::\n\n```{.r .cell-code}\n# Both direction selection\nboth = step(model_intercept, direction = 'both', scope = formula(model_full), trace = 0)\nsummary(both)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ wt + cyl + hp + am, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9387 -1.2560 -0.4013  1.1253  5.0513 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 33.70832    2.60489  12.940 7.73e-13 ***\nwt          -2.49683    0.88559  -2.819  0.00908 ** \ncyl6        -3.03134    1.40728  -2.154  0.04068 *  \ncyl8        -2.16368    2.28425  -0.947  0.35225    \nhp          -0.03211    0.01369  -2.345  0.02693 *  \nam1          1.80921    1.39630   1.296  0.20646    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.41 on 26 degrees of freedom\nMultiple R-squared:  0.8659,\tAdjusted R-squared:  0.8401 \nF-statistic: 33.57 on 5 and 26 DF,  p-value: 1.506e-10\n```\n\n\n:::\n:::\n\n\n\n7.  Validasi Model\n\n    Evaluasi model dengan menggunakan metode cross-validation atau\n    melihat pengaruh outliers.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- nrow(mtcars)\nk <- 5  # Jumlah fold\nfolds <- sample(rep(1:k, length.out = n))\n\nerrors <- numeric(k)\n\nfor (i in 1:k) {\n  train_data <- mtcars[folds != i, ]\n  test_data <- mtcars[folds == i, ]\n  \n  model <- lm(mpg ~ disp + hp + wt, data = train_data)\n  predictions <- predict(model, newdata = test_data)\n  \n  errors[i] <- mean((test_data$mpg - predictions)^2)\n}\n\nmean_cv_error <- mean(errors)\nprint(mean_cv_error)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.327748\n```\n\n\n:::\n:::\n\n\n\nNilai mean_cv_error adalah rata-rata dari Mean Squared Error (MSE) pada\ntiap fold selama cross-validation. Semakin kecil nilainya akan semakin\nbaik, yang berarti model membuat prediksi yang lebih akurat pada data\nbaru. Respectively, nilai yang besar mengindikasikan bahwa model mungkin\nmemiliki masalah, seperti underfitting (model tidak cukup kompleks) atau\noverfitting (model terlalu kompleks dan tidak mampu melakukan\ngeneralisasi dengan baik).\n\n-   Nilai mean_cv_error sebesar 9 cukup baik atau tidak tergantung pada\n    konteks dan skala data. Jika variabel targte (mpg) dalam dataset\n    mtcars memiliki kisaran nilai yang relatif besar, maka MSE sebesar 9\n    mungkin dapat diterima. Namun, jika kisaran nilai mpg kecil, maka\n    MSE sebesar 9 bisa dianggap tinggi dan kurang baik yang\n    mengindikasikan model tidak cukup akurat.\n\n# Model Validation\n\nApa Itu Model Validation? Model validation adalah proses mengevaluasi\nmodel yang telah dibangun untuk memastikan bahwa model yang dibangun\ntidak hanya akurat untuk data pelatihan, tetapi juga andal dan stabil\nsaat digunakan pada data lain.\n\nKenapa Proses Ini Penting? Proses validasi model sangat penting karena\nmemungkinkan kita untuk mengevaluasi ketahanan model saat digunakan pada\ndata baru. Model yang bekerja dengan baik pada data pelatihan mungkin\ntidak berkinerja sama baiknya pada data yang berbeda, terutama jika\nmodel tersebut terlalu \"cocok\" atau overfit dengan data pelatihan.\nValidasi ini penting agar model dapat digunakan untuk prediksi atau\npengambilan keputusan di dunia nyata tanpa menghasilkan hasil yang bias\natau tidak akurat.\n\nLangkah-langkah dalam Model Validation:\n\n-   Evaluasi Nilai Prediksi: Memeriksa hasil prediksi untuk memastikan\n    bahwa nilainya masuk akal dan tidak menunjukkan pola atau prediksi\n    yang aneh. Ini membantu mendeteksi apakah model menghasilkan\n    prediksi yang valid dan logis.\n\n-   Pemeriksaan Parameter Model: Mengevaluasi koefisien yang dihasilkan\n    oleh model untuk memastikan bahwa tanda (positif atau negatif) dan\n    besaran koefisien sesuai dengan harapan. Koefisien yang tidak stabil\n    dapat menjadi tanda bahwa model mungkin tidak bekerja baik pada data\n    baru.\n\n-   Cross-Validation (Data-Splitting): Memisahkan data menjadi data\n    training dan data testing untuk menilai performa model pada data\n    yang tidak dilihat selama pelatihan. Cross-validation mengukur\n    ketahanan model dengan mengevaluasi rata-rata kesalahan prediksi\n    pada data testing.\n\n-   Jackknifing: Teknik yang digunakan ketika ukuran data terlalu kecil\n    untuk dipecah menjadi data training dan data testing. Metode ini\n    melibatkan penghilangan satu observasi secara bergantian dan\n    menghitung prediksi untuk masing-masing kasus, lalu menganalisis\n    performanya.\n\n-   Pengumpulan Data Baru untuk Prediksi: Menguji model dengan data baru\n    yang berbeda dari data training Dengan membandingkan prediksi model\n    dengan data nyata yang baru, kita dapat mengukur seberapa baik model\n    bekerja dalam praktik nyata.\n\n## Penerapan Model Validation\n\n1.  Membuat Model Regresi\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata('CigarettesB')\nmodel = lm(packs ~ price + income, data = CigarettesB)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = packs ~ price + income, data = CigarettesB)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.41867 -0.10683  0.00757  0.11738  0.32868 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   4.2997     0.9089   4.730 2.43e-05 ***\nprice        -1.3383     0.3246  -4.123 0.000168 ***\nincome        0.1724     0.1968   0.876 0.385818    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1634 on 43 degrees of freedom\nMultiple R-squared:  0.3037,\tAdjusted R-squared:  0.2713 \nF-statistic: 9.378 on 2 and 43 DF,  p-value: 0.0004168\n```\n\n\n:::\n:::\n\n\n\n2.  Evaluasi Plot Diagnostik\n    -   Pada gambar ketiga yang menganalisis pola heteroskedastisitas\n        pada model menunjukkan bahwa meskipun titik-titik tidak\n        sepenuhnya mengikuti garis horizontal dengan distribusi yang\n        merata, plot ini menunjukkan adanya potensi heteroskedastisitas\n        dalam model.\n\n    -   Plot keempat yang merupakan plot Cook's distance digunakan untuk\n        mengidentifikasi pengamatan (observasi) yang memiliki pengaruh\n        besar terhadap model regresi. Pengamatan dengan nilai Cook's\n        Distance yang tinggi menunjukkan bahwa mereka memiliki dampak\n        signifikan terhadap koefisien regresi dan mungkin menjadi\n        outlier atau pengamatan berpengaruh. Pengamatan UT memiliki\n        Cook's Distance tertinggi, menunjukkan bahwa ini adalah\n        pengamatan paling berpengaruh dalam model. AR dan KY juga\n        menunjukkan nilai yang cukup tinggi, yang berarti mereka juga\n        mempengaruhi hasil regresi.\n\n    -   Plot Residuals vs Leverage digunakan untuk mengidentifikasi\n        pengamatan yang memiliki leverage tinggi (pengaruh besar pada\n        model) dan residual yang besar (outliers). Garis melengkung\n        (Cook's Distance) membantu menilai seberapa besar pengaruh\n        pengamatan terhadap model. Pengamatan KY perlu diperiksa lebih\n        lanjut untuk menentukan apakah ada alasan sah untuk pengaruhnya\n        yang besar. Jika pengaruh ini tidak dapat dijustifikasi, dapat\n        dipertimbangkan untuk memodifikasi model atau menghapus\n        pengamatan tersebut. Pengamatan lainnya seperti AR dan UT perlu\n        dipertimbangkan, tetapi perhatian utama harus diberikan pada\n        pengamatan dengan leverage tinggi seperti KY.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(model, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-9-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-9-4.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-9-5.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-9-6.png){width=672}\n:::\n:::\n\n\n\n3.  Deteksi Observasi Berpengaruh (Leverage dan Cook's Distance)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_hat = hatvalues(model)\nplot(model_hat)\nabline(h = c(1, 2, 3) * mean(model_hat), col = 2)\nid = which(model_hat > (2 * mean(model_hat)))\ntext(id, model_hat[id], rownames(CigarettesB)[id], pos = 1, xpd = TRUE)\n```\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n4.  Analisis Influence Measures\n    -   dfb.1\\_, dfb.pric, dfb.incm disebut dengan DFBETAS, yang\n        mengukur pengaruh pengamatan individu pada koefisien regresi.\n        Menunjukkan seberapa besar koefisien regresi akan berubah jika\n        pengamatan tersebut dihapus.\n\n    -   dffit disebut DFITS, yaitu ukuran seberapa besar pengaruh\n        pengamatan terhadap prediksi model. Nilai dffit yang besar\n        (lebih dari +-2\\*sqrt(p/n). =\\> Pengamatan KY dan UT memiliki\n        nilai dffit yang signifikan (ditandai dengan \\*\\_)\n        mengindikasikan bahwa mereka mempengaruhi prediksi model secara\n        substansial.\n\n    -   cov.r merupakan rasio covariance yang mengukur stabilitas\n        covariance dari parameter model ketika pengamatan dihapus. Nilai\n        cov.r yang jauh dari 1 menunjukkan adanya pengaruh besar dari\n        pengamatan tersebut =\\> UT memiliki nilai cov.r yang lebih\n        rendah dari 1 (0.68\\_\\*) yang mengindikasikan bahwa pengamatan\n        ini mempengaruhi stabilitas model secara signifikan.\n\n    -   cook.d merupakan Cook's Distance yang merupakan ukuran\n        keseluruhan pengaruh pengamatan pada model regresi. KY dan UT\n        memiliki nilai cook.d cukup tinggi (0.21 dan 0.22) menunjukkan\n        bahwa mereka memiliki pengaruh signifikan terhadap hasil model.\n\n    -   hat (leverage) mengukur seberapa jauh pengamatan tertentu dari\n        nilai rata-rata variabel prediktor. KY memiliki leverage tinggi\n        (0.20\\_\\*) yang berarti pengamatan ini jauh dari nilai rata-rata\n        variabel independen dan dapat mempengaruhi hasil model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(influence.measures(model))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPotentially influential observations of\n\t lm(formula = packs ~ price + income, data = CigarettesB) :\n\n   dfb.1_ dfb.pric dfb.incm dffit   cov.r   cook.d hat    \nCT  0.15  -0.02    -0.15    -0.20    1.22_*  0.01   0.14  \nKY -0.09  -0.73     0.15     0.81_*  1.11    0.21   0.20_*\nNJ  0.13   0.00    -0.12    -0.16    1.23_*  0.01   0.14  \nUT -0.78  -0.32     0.76    -0.89_*  0.68_*  0.22   0.09  \n```\n\n\n:::\n:::\n\n\n\n5.  Mengidentifikasi dan Menghapus Observasi Berpengaruh\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidx = which(apply(influence.measures(model)$is.inf, 1, any))\nCigarettesB[idx, ]  # Menampilkan observasi berpengaruh\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     packs    price  income\nCT 4.66983  0.32149 5.09472\nKY 5.37906 -0.03260 4.64937\nNJ 4.70633  0.30901 5.10268\nUT 4.40859  0.19260 4.55586\n```\n\n\n:::\n\n```{.r .cell-code}\nCigarettesB_noinf = CigarettesB[-idx, ]  # Dataset tanpa observasi berpengaruh\n```\n:::\n\n\n\n6.  Membuat Model Baru Tanpa Observasi Berpengaruh\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_noinf = lm(packs ~ price + income, data = CigarettesB_noinf)\nsummary(model_noinf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = packs ~ price + income, data = CigarettesB_noinf)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.303038 -0.108141 -0.006607  0.112727  0.292133 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.77720    0.96505   4.950 1.47e-05 ***\nprice       -1.00581    0.32910  -3.056  0.00403 ** \nincome       0.05946    0.20788   0.286  0.77637    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1505 on 39 degrees of freedom\nMultiple R-squared:  0.2128,\tAdjusted R-squared:  0.1724 \nF-statistic: 5.271 on 2 and 39 DF,  p-value: 0.009414\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(model_noinf, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-13-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-13-4.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-13-5.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modul4_files/figure-html/unnamed-chunk-13-6.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary(influence.measures(model_noinf))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPotentially influential observations of\n\t lm(formula = packs ~ price + income, data = CigarettesB_noinf) :\nNONE\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nnumeric(0)\n```\n\n\n:::\n:::\n\n\n\n7.  Cross-Validation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- nrow(CigarettesB)\nk <- 5  # Jumlah fold\nfolds <- sample(rep(1:k, length.out = n))\n\nerrors <- numeric(k)\n\nfor (i in 1:k) {\n  train_data <- CigarettesB[folds != i, ]\n  test_data <- CigarettesB[folds == i, ]\n  \n  model_cv <- lm(packs ~ price + income, data = train_data)\n  predictions <- predict(model_cv, newdata = test_data)\n  \n  # Hitung Mean Squared Error (MSE) pada data uji\n  errors[i] <- mean((test_data$packs - predictions)^2)\n}\n\nmean_cv_error <- mean(errors)\nprint(mean_cv_error)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03025302\n```\n\n\n:::\n:::\n",
    "supporting": [
      "modul4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}